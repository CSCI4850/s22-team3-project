{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c9704b-bdcb-4248-9224-3cd94571a09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q \"tensorflow-text==2.8.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9405d31e-3b31-47d0-8cb0-776d721b301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "33eb7a0c-a52e-4b68-8238-d687c481274c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The important thing is not to stop questioning. Curiosity has its own reason for existence. One cannot help but be in awe when he contemplates the mysteries of eternity, of life, of the marvelous structure of reality. It is enough if one tries merely to comprehend a little of this mystery each day.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Open data\n",
    "data_file = open('Data.txt').read()\n",
    "data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9448eef1-72e2-488e-92b9-f824abd90d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create tokenizer object\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "#Convert data to lowercase\n",
    "data = data_file.lower().split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "597491c5-b43d-4e5e-a4c5-7e4c8eb764e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'of': 1, 'the': 2, 'is': 3, 'to': 4, 'one': 5, 'important': 6, 'thing': 7, 'not': 8, 'stop': 9, 'questioning': 10, 'curiosity': 11, 'has': 12, 'its': 13, 'own': 14, 'reason': 15, 'for': 16, 'existence': 17, 'cannot': 18, 'help': 19, 'but': 20, 'be': 21, 'in': 22, 'awe': 23, 'when': 24, 'he': 25, 'contemplates': 26, 'mysteries': 27, 'eternity': 28, 'life': 29, 'marvelous': 30, 'structure': 31, 'reality': 32, 'it': 33, 'enough': 34, 'if': 35, 'tries': 36, 'merely': 37, 'comprehend': 38, 'a': 39, 'little': 40, 'this': 41, 'mystery': 42, 'each': 43, 'day': 44} \n",
      "\n",
      "[[2, 6, 7, 3, 8, 4, 9, 10], [11, 12, 13, 14, 15, 16, 17], [5, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2, 27, 1, 28, 1, 29, 1, 2, 30, 31, 1, 32], [33, 3, 34, 35, 5, 36, 37, 4, 38, 39, 40, 1, 41, 42, 43, 44], []] \n",
      "\n",
      "45 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create dictionary of words with the frequency they occur\n",
    "#Every word gets unique value > 0\n",
    "#0 is reserved for padding\n",
    "tokenizer.fit_on_texts(data)\n",
    "\n",
    "#Transforms sentences into set of integers from the dictionary\n",
    "input_sequences = tokenizer.texts_to_sequences(data)\n",
    "\n",
    "#Counts total words\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "#Prints it all out\n",
    "print(tokenizer.word_index, '\\n')\n",
    "print(input_sequences, '\\n')\n",
    "print(total_words, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15c25582-4522-4342-b432-d95b67856fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pad sequences\n",
    "input_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen = 20, padding ='post', value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9cfecd8e-06e8-4def-a00a-1a28b262cc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 20)\n",
      "[[ 2  6  7  3  8  4  9 10  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [11 12 13 14 15 16 17  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [19 20 21 22 23 24 25 26  2 27  1 28  1 29  1  2 30 31  1 32]\n",
      " [33  3 34 35  5 36 37  4 38 39 40  1 41 42 43 44  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "input_sequences = np.array(input_sequences)\n",
    "print(input_sequences.shape)\n",
    "print(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7632a936-695c-4b42-a829-25f1930c30ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 20)\n",
      "[[11 12 13 14 15 16 17  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [19 20 21 22 23 24 25 26  2 27  1 28  1 29  1  2 30 31  1 32]\n",
      " [33  3 34 35  5 36 37  4 38 39 40  1 41 42 43 44  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "#Shift array by one to create targets \n",
    "output_sequences = np.array(np.roll(input_sequences, 4))\n",
    "output_sequences = tf.keras.preprocessing.sequence.pad_sequences(output_sequences, maxlen = 20, padding ='post', value = 0)\n",
    "output_sequences[-1] = 0\n",
    "print(output_sequences.shape)\n",
    "print(output_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c755f1c5-0316-48f7-9b3c-a61bc93a1812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 1329, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 512 and 20 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential_4/embedding_10/embedding_lookup/Identity_1, mean_squared_error/Cast)' with input shapes: [1,20,512], [1,20].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2069153/1207664958.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexpand_nested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m history = embedding_model.fit(\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 1329, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 512 and 20 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential_4/embedding_10/embedding_lookup/Identity_1, mean_squared_error/Cast)' with input shapes: [1,20,512], [1,20].\n"
     ]
    }
   ],
   "source": [
    "#Convert to embedding vectors\n",
    "embedding_model = keras.Sequential()\n",
    "\n",
    "embedding_model.add(keras.layers.Embedding(20, 512, mask_zero = True, input_length = 20)\n",
    "\n",
    "embedding_model.compile(loss=keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Nadam(), metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "                    \n",
    "keras.utils.plot_model(embedding_model,to_file='model.png', show_shapes=True,expand_nested=True)\n",
    "\n",
    "history = embedding_model.fit(\n",
    "  sequences, sequences,\n",
    "  batch_size=1,\n",
    "  epochs=10)\n",
    "word_vectors = embedding_model.predict(sequences)\n",
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e7a15e-785f-4ed3-8915-76a53ec45c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate positional encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d812e7f8-f002-4903-94e2-848e44cefc90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
