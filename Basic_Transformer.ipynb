{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c9704b-bdcb-4248-9224-3cd94571a09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q \"tensorflow-text==2.8.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9405d31e-3b31-47d0-8cb0-776d721b301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33eb7a0c-a52e-4b68-8238-d687c481274c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The important thing is not to stop questioning. Curiosity has its own reason for existence. One cannot help but be in awe when he contemplates the mysteries of eternity, of life, of the marvelous structure of reality. It is enough if one tries merely to comprehend a little of this mystery each day.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Open data\n",
    "data_file = open('Data.txt').read()\n",
    "data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9448eef1-72e2-488e-92b9-f824abd90d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create tokenizer object\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "#Convert data to lowercase\n",
    "data = data_file.lower().split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "597491c5-b43d-4e5e-a4c5-7e4c8eb764e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'of': 1, 'the': 2, 'is': 3, 'to': 4, 'one': 5, 'important': 6, 'thing': 7, 'not': 8, 'stop': 9, 'questioning': 10, 'curiosity': 11, 'has': 12, 'its': 13, 'own': 14, 'reason': 15, 'for': 16, 'existence': 17, 'cannot': 18, 'help': 19, 'but': 20, 'be': 21, 'in': 22, 'awe': 23, 'when': 24, 'he': 25, 'contemplates': 26, 'mysteries': 27, 'eternity': 28, 'life': 29, 'marvelous': 30, 'structure': 31, 'reality': 32, 'it': 33, 'enough': 34, 'if': 35, 'tries': 36, 'merely': 37, 'comprehend': 38, 'a': 39, 'little': 40, 'this': 41, 'mystery': 42, 'each': 43, 'day': 44} \n",
      "\n",
      "[[2, 6, 7, 3, 8, 4, 9, 10], [11, 12, 13, 14, 15, 16, 17], [5, 18, 19, 20, 21, 22, 23, 24, 25, 26, 2, 27, 1, 28, 1, 29, 1, 2, 30, 31, 1, 32], [33, 3, 34, 35, 5, 36, 37, 4, 38, 39, 40, 1, 41, 42, 43, 44], []] \n",
      "\n",
      "45 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create dictionary of words with the frequency they occur\n",
    "#Every word gets unique value > 0\n",
    "#0 is reserved for padding\n",
    "tokenizer.fit_on_texts(data)\n",
    "\n",
    "#Transforms sentences into set of integers from the dictionary\n",
    "input_sequences = tokenizer.texts_to_sequences(data)\n",
    "\n",
    "#Counts total words\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "#Prints it all out\n",
    "print(tokenizer.word_index, '\\n')\n",
    "print(input_sequences, '\\n')\n",
    "print(total_words, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c25582-4522-4342-b432-d95b67856fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  6,  7,  3,  8,  4,  9, 10,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [11, 12, 13, 14, 15, 16, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [19, 20, 21, 22, 23, 24, 25, 26,  2, 27,  1, 28,  1, 29,  1,  2,\n",
       "        30, 31,  1, 32],\n",
       "       [33,  3, 34, 35,  5, 36, 37,  4, 38, 39, 40,  1, 41, 42, 43, 44,\n",
       "         0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pad sequences\n",
    "input_sequences = tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen = 20, padding ='post', value = 0)\n",
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cfecd8e-06e8-4def-a00a-1a28b262cc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 20)\n",
      "[[ 2  6  7  3  8  4  9 10  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [11 12 13 14 15 16 17  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [19 20 21 22 23 24 25 26  2 27  1 28  1 29  1  2 30 31  1 32]\n",
      " [33  3 34 35  5 36 37  4 38 39 40  1 41 42 43 44  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "input_sequences = np.array(input_sequences)\n",
    "print(input_sequences.shape)\n",
    "print(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7632a936-695c-4b42-a829-25f1930c30ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 20)\n",
      "[[11 12 13 14 15 16 17  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [19 20 21 22 23 24 25 26  2 27  1 28  1 29  1  2 30 31  1 32]\n",
      " [33  3 34 35  5 36 37  4 38 39 40  1 41 42 43 44  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "#Shift array by one to create targets \n",
    "output_sequences = np.array(np.roll(input_sequences, 80))\n",
    "output_sequences[-1] = 0\n",
    "print(output_sequences.shape)\n",
    "print(output_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f6eb672-9c0d-46d4-babc-c6ecfad50b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = input_sequences.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe46006c-1491-48d2-b31f-2979293d738d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape = output_sequences.shape[1:]\n",
    "output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c481ded-f750-4041-b4f2-f501864087f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = tf.convert_to_tensor(input_sequences)\n",
    "output_sequences = tf.convert_to_tensor(output_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c755f1c5-0316-48f7-9b3c-a61bc93a1812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0454743 ,  0.02437179, -0.01975303, ..., -0.04093369,\n",
       "        -0.01609544,  0.01044757],\n",
       "       [ 0.03825822,  0.02885522,  0.03115452, ..., -0.04093369,\n",
       "        -0.01609544,  0.01044757],\n",
       "       [ 0.03394261,  0.01523543,  0.03496403, ...,  0.04506305,\n",
       "        -0.02487865, -0.00269923],\n",
       "       [-0.00072331,  0.04929391,  0.00960779, ..., -0.04093369,\n",
       "        -0.01609544,  0.01044757],\n",
       "       [ 0.02883116,  0.02487377, -0.02857069, ..., -0.04093369,\n",
       "        -0.01609544,  0.01044757]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to embedding vectors\n",
    "#embedding_model = keras.Sequential()\n",
    "\n",
    "input = keras.layers.Input(shape = input_sequences.shape)\n",
    "\n",
    "word_input = keras.layers.Input(shape = input_sequences.shape[1])\n",
    "\n",
    "embedding_layer = keras.layers.Embedding(input_dim = total_words, output_dim = 512, mask_zero = True, input_length = input_sequences.shape[1])(word_input) \n",
    "\n",
    "word_vectors = keras.layers.Flatten()(embedding_layer)\n",
    "\n",
    "embedding_model = keras.Model(word_input, word_vectors)\n",
    "\n",
    "embedding_model.compile(loss=keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(), metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "                    \n",
    "keras.utils.plot_model(embedding_model,to_file='model.png', show_shapes=True,expand_nested=True)\n",
    "\n",
    "word_vectors = embedding_model.predict(input_sequences)\n",
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e7a15e-785f-4ed3-8915-76a53ec45c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate positional encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d812e7f8-f002-4903-94e2-848e44cefc90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
